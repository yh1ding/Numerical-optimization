{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PG and APG for Lasso.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgOGwm4pUdun"
      },
      "source": [
        "# Magnetic Resonance Imaging "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgKKcz6hn6Yh"
      },
      "source": [
        "## Looking Ahead\n",
        "\n",
        "In the previous example, we verified that an example MR image from a dataset was sparse in the wavelet domain, after we transformed it from the spatial domain. In this example, we will exploit this sparsity in order to recover the MR image from compressive measurements. Recall that MR images are, at acquisition time, obtained in the Fourier domain; this has implications for the measurement map that we construct in a compressed sensing setup. Please review the homework writeup for a discussion of these issues and a justification for the sensing model we implement below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRMqlNmOog-_"
      },
      "source": [
        "## Loading the Data\n",
        "\n",
        "We use the same code from the previous notebook to load in the data. As before, we will focus on a single sagittarial slice of the patient's anatomical data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8CwHEnLUhYg"
      },
      "source": [
        "## Install AWS CLI tools\n",
        "!pip install awscli\n",
        "## Prepare data directory\n",
        "import os\n",
        "os.chdir('/content')\n",
        "!mkdir bold5000\n",
        "os.chdir('/content/bold5000')\n",
        "\n",
        "## Grab the data\n",
        "#!aws s3 sync --no-sign-request --exclude \"*\" --include \"*06*\" s3://openneuro.org/ds001499/derivatives/fmriprep/sub-CSI3/ses-13/func/ /content/bold5000/sub-CSI3_ses-13_run-06/\n",
        "!aws s3 sync --no-sign-request s3://openneuro.org/ds001499/sub-CSI3/ses-16/anat/ /content/bold5000/sub-CSI3_anat/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHoGlw82o019"
      },
      "source": [
        "We add the same auxiliary definitions as last time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6juFjggos7N"
      },
      "source": [
        "## Auxiliary code for our wavelet experiments\n",
        "import bokeh\n",
        "import bokeh.plotting as bpl\n",
        "from bokeh.models import ColorBar, BasicTicker, LinearColorMapper\n",
        "import pywt\n",
        "\n",
        "## Try to do something like imagesc in MATLAB using Bokeh tools.\n",
        "def imagesc(M, title=''):\n",
        "  m, n = M.shape\n",
        "  \n",
        "  # 600 px should be good; calculate ph to try to get aspect ratio right\n",
        "  pw = 600\n",
        "  ph = round(1.0 * pw * m / n)\n",
        "  h = bpl.figure(plot_width = pw, plot_height = ph, x_range=(0, 1.0*n),\n",
        "                 y_range=(0, 1.0*m), toolbar_location='below',\n",
        "                 title=title, match_aspect=True\n",
        "                )\n",
        "  \n",
        "  minval = np.min(M)\n",
        "  maxval = np.max(M)\n",
        "  \n",
        "  color_mapper = LinearColorMapper(palette=\"Greys256\", low=minval, high=maxval)\n",
        "  h.image(image=[M], x=0, y=0, dw=1.0*n, dh=1.0*m, color_mapper=color_mapper)\n",
        "  \n",
        "  color_bar = ColorBar(color_mapper=color_mapper, ticker=BasicTicker(),\n",
        "                      label_standoff=12, border_line_color=None, location=(0, 0))\n",
        "  \n",
        "  h.add_layout(color_bar, 'right')\n",
        "  \n",
        "\n",
        "  bpl.show(h)\n",
        "  return h\n",
        "\n",
        "## Wavelet functions below\n",
        "## Note: we expect all image sizes to be powers-of-two and square!\n",
        "## So if you adapt this code, be sure to fix this or enforce this requirement...\n",
        "\n",
        "# Get a default slice object for a multilevel wavelet transform\n",
        "# Used to abstract this annoying notation out of the transform...\n",
        "def default_slices(levels, n):\n",
        "  c = pywt.wavedec2(np.zeros((n, n)), 'db4', mode='periodization', level=levels)\n",
        "  bye, slices = pywt.coeffs_to_array(c)\n",
        "  return slices\n",
        "\n",
        "# Wrapper for forward discrete wavelet transform\n",
        "# Output data as a matrix (we don't care about tuple format)\n",
        "def dwt(levels, sdom_data):\n",
        "  c = pywt.wavedec2(sdom_data, 'db4', mode='periodization', level=levels)\n",
        "  output, bye = pywt.coeffs_to_array(c)\n",
        "  return output\n",
        "\n",
        "# Wrapper for inverse discrete wavelet transform\n",
        "# Expect wdom_data as a matrix (we don't care about tuple format)\n",
        "def idwt(levels, wdom_data, slices=None):\n",
        "  n = wdom_data.shape[0]\n",
        "  if slices is None:\n",
        "    slices = default_slices(levels, n)\n",
        "  c = pywt.array_to_coeffs(wdom_data, slices, output_format='wavedec2')\n",
        "  return pywt.waverec2(c, 'db4', mode='periodization')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0JLX_RCo3Ox"
      },
      "source": [
        "We finally extract the sagittarial slice we will study. Again, same as last time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhrVIMQoo6vi"
      },
      "source": [
        "import numpy as np\n",
        "import nibabel as nib\n",
        "\n",
        "img = nib.load('/content/bold5000/sub-CSI3_anat/sub-CSI3_ses-16_T1w.nii.gz')\n",
        "\n",
        "data = img.get_fdata()\n",
        "\n",
        "## Store dimensions\n",
        "Nx = data.shape[0]\n",
        "Ny = data.shape[1]\n",
        "Nz = data.shape[2]\n",
        "n = Ny\n",
        "X = data[Nx//2, :, :];\n",
        "\n",
        "bpl.output_notebook()\n",
        "imagesc(data[Nx//2, :, :], title='MR Image We Will Recover')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H38FuC6UpXFs"
      },
      "source": [
        "## Implementing the Measurement Model\n",
        "\n",
        "An MR machine collects samples of the 2D Fourier transformation of the underlying spatial profile (e.g., the figure above). An MR machine that employs compressive sensing does the same, but collects far fewer than the `n ** 2` measurements necessary to exactly represent the image at the resolution we are using above. From the lecture, we know that such subsampling leads to an incoherent measurement map when the sampling is done randomly; and we expect thus that L1 minimization will work for recovery from the compressive measurements.\n",
        "\n",
        "The measurement model we will implement here is the Bernoulli one described in the homework handout. We will implement this below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yajMQueDqZn_"
      },
      "source": [
        "## Create the index set for our mapping\n",
        "p = 0.3  # bernoulli distribution parameter\n",
        "Omega = {}# We define Omega here to contain all the indices to _delete_\n",
        "for idx_i in np.arange(n):\n",
        "  for idx_j in np.arange(n):\n",
        "    coin = np.random.rand(1,)\n",
        "    if coin > p:\n",
        "      Omega[(idx_i, idx_j)] = 1\n",
        "idxs = np.asarray(list(Omega.keys()))\n",
        "len(X[idxs[:,0], idxs[:,1]]) # Index like this\n",
        "\n",
        "## Create the operator\n",
        "levels = 2\n",
        "def meas_map(mtx):\n",
        "  pre_proj = np.fft.fft2(idwt(levels, mtx), norm=\"ortho\")\n",
        "  pre_proj[idxs[:, 0], idxs[:, 1]] = 0\n",
        "  return pre_proj\n",
        "def meas_map_adj(mtx):\n",
        "  mtx[idxs[:, 0], idxs[:, 1]] = 0\n",
        "  return dwt(levels, np.fft.ifft2(mtx, norm=\"ortho\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GNYWpRsyIkc"
      },
      "source": [
        "## Performing Sparse Recovery\n",
        "\n",
        "We generate observations `Y` from our input `X` and the measurement map. In particular, we first get the sparse coefficients `S` for our image, and then transform them in order to match with the measurement model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkzb0eZ2yU3K"
      },
      "source": [
        "S = dwt(levels, X)\n",
        "Y = meas_map(S)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUVr_jaHz0ge"
      },
      "source": [
        "We plot a few observations of our image below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXxXDbAyz1xv"
      },
      "source": [
        "bpl.output_notebook()\n",
        "imagesc(np.fft.fftshift(np.abs(np.fft.fft2(X/n**2))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWLNn3UQz4xF"
      },
      "source": [
        "Above is the normalized 2D FFT of the image `X`, shifted to have low frequencies in the center of the image. We see that nearly all the frequency content is localized in the low frequencies, and the image appears quite sparse! However, the Fourier phase contains a *lot* of information about the image: reconstructing as we did in the previous homework using large-magnitude wavelet coefficients (but with large magnitude Fourier coefficients here) gives a small squared-error, but a result with poor visual quality, as we can see in the figure below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0czKyoZ1Nqz"
      },
      "source": [
        "F = np.fft.fft2(X)\n",
        "absmags = np.absolute(F.flatten())\n",
        "idxs_absmag = np.argsort(absmags)\n",
        "idxs_absmag = idxs_absmag[::-1] \n",
        "\n",
        "num_keep = 8000\n",
        "F_copy = np.copy(F)\n",
        "F_copy[np.unravel_index(idxs_absmag[num_keep:], (n, n))] = 0\n",
        "X_reconstr = np.fft.ifft2(F_copy)\n",
        "\n",
        "bpl.output_notebook()\n",
        "imagesc(np.abs(X_reconstr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdK7NxnM2bp3"
      },
      "source": [
        "This is what motivates us to use the wavelet transform, and its corresponding notion of sparsity, in our measurement map."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SHd1d7U3OVf"
      },
      "source": [
        "## Your Tasks\n",
        "\n",
        "Complete each of the tasks in the level three headers below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3Eq4zZJ3SSM"
      },
      "source": [
        "### Task 1: Sparse Recovery with Proximal Gradient\n",
        "\n",
        "For this task, you should implement the proximal gradient descent algorithm for the LASSO objective with the measurement map we have specified in this problem and in the theoretical setting sketched in the homework writeup. Your algorithm will be quite similar to the algorithm you wrote (or will write) for the spectrum sensing application, but you will need to make the necessary changes to the matrix-vector multiplications to accommodate the \"matrix linear maps\" in this problem.\n",
        "\n",
        "See the first task's description in the spectrum sensing problem for hints about how to code and debug your proximal gradient descent algorithm.\n",
        "\n",
        "**Hint**: Be sure your choice of initialization matches the scale of the data `Y`. A good practice is to use Gaussian initialization, such that the expected Frobenius norm of the initialization matrix is around 1; then also scale the matrix `Y` to have Frobenius norm 1. You can restore the original scale after you solve the optimization problem.\n",
        "\n",
        "**Hint**: The algorithm can take a while to run. To speed things up, for the purpose of testing you may want to downsample the input MR image, so that instead of being `256 x 256` it is e.g. `64 x 64`. Be sure to keep the sizes as powers of two, or the wavelet transform code will break. This will also help with experimenting to find the best setting of the sparsifying parameter `lambda`: it plays a very large role in the visual quality of the signal you reconstruct."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhUMQ9De3qtM"
      },
      "source": [
        "### Task 2: Assessing Performance\n",
        "\n",
        "Complete the following performance evaluation tasks for your sparse recovery algorithm:\n",
        "1. For at least 3 values of the Bernoulli parameter `p`, say `[0.1, 0.2, 0.4, 0.5, 0.7]`, perform at least 3 independent trials of the sparse recovery experiment. Here, \"independent trials\" means you should re-generate the measurement map in each separate experiment. For each experiment, calculate the mean squared error between your LASSO solver's output and the ground truth image `X` (make sure they are in the same domain!), and average the mean squared errors for each setting of `p` over the independent trials. Output a plot of these averaged mean squared errors as a function of `p`; include error bars corresponding to the trial variances.\n",
        "2. How large do you need `p` to be before you get acceptable (in terms of both MSE and in terms of visual quality) results for the sparse recovery experiment? Can you give an explanation for why the performance may be worse here than in other experiments in terms of properties of the specific measurement map we use here?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDVGbHYNPnFO"
      },
      "source": [
        "## Solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NormWcosf9uo"
      },
      "source": [
        "### Task 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISKF_cuUf_dQ"
      },
      "source": [
        "We give the code for performing proximal gradient on the matrix LASSO objective below.\n",
        "\n",
        "A challenging aspect of this problem is that the problem size (essentially $n = 2^{16}$) makes convergence slow, and initialization plays a role in the speed of convergence. Also, for small $p$, there are problem instances (realizations of the set $\\Omega$) that are not well-posed. In the solution we will demonstrate two ways to get around this. One is to implement a biased initialization using the pseudoinverse, which in this context reduces to `X = meas_map_adj(Y)`; it does not speed up convergence much, but it gets rid of the randomness in rate of convergence associated with a naive random initialization. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4udTZaHGPpYO"
      },
      "source": [
        "## Prox Gradient\n",
        "def soft_thresh(x, lambd):\n",
        "  return np.maximum(x - lambd, np.zeros_like(x))\n",
        "\n",
        "def prox_l1(x, lambd):\n",
        "  phases = np.angle(x)\n",
        "  mags = np.abs(x)\n",
        "  thresholded = soft_thresh(mags, lambd)\n",
        "  return thresholded * np.exp(1j * phases)\n",
        "\n",
        "def objective(x, A, y):\n",
        "  return 0.5 * np.linalg.norm(y - A(x), ord='fro')**2\n",
        "    \n",
        "def pg_lasso(Y, A, A_adj, lambd):\n",
        "  lip = 1\n",
        "  alpha = 0.5 * 1/lip\n",
        "  MAX_ITER = int(2e3)\n",
        "  TOL = 1e-8\n",
        "  ZERO_TOL = 1e-6\n",
        "  S_init = 1/n * np.random.randn(n,n)\n",
        "  # S_init = A_adj(Y)\n",
        "  \n",
        "  pt = S_init\n",
        "  obj = np.zeros((MAX_ITER,))\n",
        "\n",
        "  for iteration in range(MAX_ITER):\n",
        "    # Step to aux point\n",
        "    # Compute gradient\n",
        "    grad = A_adj(A(pt) - Y)\n",
        "    # Gradient step\n",
        "    pt = prox_l1(pt - alpha * grad, alpha * lambd)\n",
        "    # Evaluate objective\n",
        "    obj[iteration] = objective(pt, A, Y) + lambd * np.linalg.norm(pt.flatten(), ord=1)\n",
        "    \n",
        "    if iteration % 1e2 == 0:\n",
        "      print('iter {}, obj {}'.format(iteration, obj[iteration]))\n",
        "    \n",
        "    # Stopping criterion\n",
        "    if iteration > 0 and np.abs(obj[iteration-1] - obj[iteration]) < TOL:\n",
        "      print('Met minimum tolerance at iter {}. Breaking.'.format(iteration))\n",
        "      break\n",
        "  \n",
        "  obj = obj[:iteration]\n",
        "  return pt, obj\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0zFpFjSjPTG"
      },
      "source": [
        "Another way to make things run smoother is to use the knowledge we have acquired since completing the homework, and apply the accelerated proximal gradient algorithm to speed up convergence. I implement here a version of this algorithm with a very simple-to-implement choice of the \"momentum parameter\" sequence $t_k$, which is worth remembering."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKocCgV2jMt1"
      },
      "source": [
        "def apg_lasso(Y, A, A_adj, lambd):\n",
        "  lip = 1\n",
        "  alpha = 1/lip\n",
        "  \n",
        "  MAX_ITER = int(1e6)\n",
        "  TOL = 1e-8\n",
        "  ZERO_TOL = 1e-6\n",
        "  S_init = 1/n * np.random.randn(n,n)\n",
        " #   S_init = A_adj(Y)\n",
        "  \n",
        "  pt = S_init\n",
        "  pt_prev = pt\n",
        "  aux_pt = np.zeros_like(pt)\n",
        "  obj = np.zeros((MAX_ITER,))\n",
        "\n",
        "  for iteration in range(MAX_ITER):\n",
        "    # Step to aux point\n",
        "    aux_pt = pt + (iteration / (iteration + 3)) * (pt - pt_prev)\n",
        "    pt_prev = pt\n",
        "    # Compute gradient\n",
        "    grad = A_adj(A(aux_pt) - Y)\n",
        "    # Gradient step\n",
        "    pt = prox_l1(aux_pt - alpha * grad, alpha * lambd)\n",
        "\n",
        "    obj[iteration] = objective(pt, A, Y) + lambd * np.linalg.norm(pt.flatten(), ord=1)\n",
        "    \n",
        "    if iteration % 1e2 == 0:\n",
        "      print('iter {}, obj {}'.format(iteration, obj[iteration]))\n",
        "    \n",
        "    # Stopping criterion\n",
        "    if iteration > 0 and np.abs(obj[iteration-1] - obj[iteration]) < TOL:\n",
        "      print('Met minimum tolerance at iter {}. Breaking.'.format(iteration))\n",
        "      break\n",
        "  \n",
        "  obj = obj[:iteration]\n",
        "  return pt, obj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJYFJEy2khQI"
      },
      "source": [
        "We test the code below. You can try calling `pg_lasso` or `apg_lasso` and compare the difference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK9CRke7PpwX"
      },
      "source": [
        "x_try1, obj = pg_lasso(Y/np.linalg.norm(Y, ord='fro'), meas_map, meas_map_adj, 1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKC2Y56cPsWx"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.loglog(obj)\n",
        "plt.show()\n",
        "\n",
        "bpl.output_notebook()\n",
        "imagesc(np.real(idwt(levels, x_try1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjIEHJgLkn1r"
      },
      "source": [
        "### Task 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CqYe5kGk6Yh"
      },
      "source": [
        "Now we complete the evaluation tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj-vxbNek8VS"
      },
      "source": [
        "def trial(prob, lambd):\n",
        "  # Run a single trial of the experiment\n",
        "  # Copy-paste our measurement map code from above\n",
        "  Omega = {}# We define Omega here to contain all the indices to _delete_\n",
        "  for idx_i in np.arange(n):\n",
        "    for idx_j in np.arange(n):\n",
        "      coin = np.random.rand(1,)\n",
        "      if coin > prob:\n",
        "        Omega[(idx_i, idx_j)] = 1\n",
        "  idxs = np.asarray(list(Omega.keys()))\n",
        "  len(X[idxs[:,0], idxs[:,1]]) # Index like this\n",
        "\n",
        "  ## Create the operator\n",
        "  levels = 2\n",
        "  def meas_map(mtx):\n",
        "    pre_proj = np.fft.fft2(idwt(levels, mtx), norm=\"ortho\")\n",
        "    pre_proj[idxs[:, 0], idxs[:, 1]] = 0\n",
        "    return pre_proj\n",
        "  def meas_map_adj(mtx):\n",
        "    mtx[idxs[:, 0], idxs[:, 1]] = 0\n",
        "    return dwt(levels, np.fft.ifft2(mtx, norm=\"ortho\"))\n",
        "    pass\n",
        "  \n",
        "  # Take measurement\n",
        "  Y = meas_map(S)\n",
        "  \n",
        "  # Perform recovery\n",
        "  scale = np.linalg.norm(Y, ord='fro')\n",
        "  S_est, obj = apg_lasso(Y/scale, meas_map, meas_map_adj, lambd)\n",
        "  X_est = idwt(levels, scale * S_est).real\n",
        "  \n",
        "  # Output result\n",
        "  # Note that because the wavelet transform is unitary, there is no difference\n",
        "  # between comparing MSEs of S and S_est (wavelet domain) or X and X_est (spatial domain)\n",
        "  bpl.output_notebook()\n",
        "  imagesc(X_est)\n",
        "  return np.linalg.norm(X_est - X, ord='fro')**2/n**2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JHyVwUCmAsa"
      },
      "source": [
        "# Run the experiments and plot the results.\n",
        "p_vec = [0.1, 0.25, 0.35, 0.5, 0.6]\n",
        "lambda_sched = [1e-4, 1e-4, 1e-4, 1e-4, 5e-4]\n",
        "num_trials = 3\n",
        "\n",
        "nmse_results = np.zeros((len(p_vec), num_trials))\n",
        "for prob_idx in np.arange(len(p_vec)):\n",
        "  prob = p_vec[prob_idx]\n",
        "  lambd = lambda_sched[prob_idx]\n",
        "  print('- probability of keeping: {}'.format(prob))\n",
        "  for trial_idx in np.arange(num_trials):\n",
        "    print('--- trial number: {}'.format(trial_idx + 1))\n",
        "    nmse_results[prob_idx, trial_idx] = trial(prob, 1e-4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCVGrzY9oRb4"
      },
      "source": [
        "nmse = np.mean(nmse_results, axis=1)\n",
        "nmse_std = np.std(nmse_results, axis=1)\n",
        "plt.errorbar(p_vec, nmse, yerr=nmse_std)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LHLj4r_yIEJ"
      },
      "source": [
        "One may account for the large variance across trials as being due to the measurement map we employ, and occasional ill-posedness as a result of bad draws. It would be possible to further improve performance by tuning the sparsifying parameter $\\lambda$ individually for each setting of $p$. \n",
        "\n",
        "In our experiments, we can start to discern fine-detail features in the recovered image once $p$ is close to $0.5$. One way to interpret the relatively poor scaling performance in this application compared to e.g. the spectrum sensing application is that here, the measurement operator we implement (subsampling) does not have the RIP for arbitrary sparsity levels."
      ]
    }
  ]
}